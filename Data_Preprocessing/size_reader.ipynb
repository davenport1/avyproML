{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages.\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import urllib.request\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create DataFrame for Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our output file with possible size ratings as headers.\n",
    "header_names = [\"date\", \"small\", \"large\", \"very_large\", \"historic\"]\n",
    "\n",
    "# Add headers.\n",
    "df = pd.DataFrame(columns=header_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our total span, covering multiple seasons.\n",
    "years = (\"17\", \"18\", \"19\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    title = \"sizes_\" + year + \".csv\"\n",
    "    sizes = pd.read_csv(title)\n",
    "\n",
    "    # 1000 == small\n",
    "    # 0100 == large\n",
    "    # 0010 == very large\n",
    "    # 0001 == historic\n",
    "    for index, row in sizes.iterrows():\n",
    "        date = row[\"date\"][40:]\n",
    "\n",
    "        # As defined by data-source.\n",
    "        small = row[\"size_10\"]\n",
    "        large_1 = row[\"size_12\"]\n",
    "        large_2 = row[\"size_20\"]\n",
    "        very_large = row[\"size_23\"]\n",
    "\n",
    "        # Must first confirm that this entry has properly scraped data.\n",
    "        # One-hot encode size ratings.\n",
    "        if not pd.isna(very_large) or not pd.isna(large_1) or not pd.isna(large_2) or not pd.isna(small):\n",
    "            if not pd.isna(very_large):\n",
    "                entry = [date, 0, 0, 1, 0]\n",
    "            elif not pd.isna(large_1) or not pd.isna(large_2):\n",
    "                entry = [date, 0, 1, 0, 0]\n",
    "            elif not pd.isna(small):\n",
    "                entry = [date, 1, 0, 0, 0]\n",
    "            df.loc[len(df)] = entry\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort DataFrame by Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by date.\n",
    "df['date'] = pd.to_datetime(df.date, infer_datetime_format = True)\n",
    "df.sort_values(by = 'date', ascending = True, inplace = True)\n",
    "\n",
    "# Turn DataFrame into CSV.\n",
    "df.to_csv(\"sizes.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0150ad5ad973dda1cabc01bab0fdc0db78b5f921ad0cd2d7560a3f44e4650dba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
